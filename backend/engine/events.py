"""äº‹ä»¶ç±»å‹ä¸æ„å»ºå‡½æ•° â€” Agent SSE æµå¼è¾“å‡ºã€‚

æ ‡å‡†åŒ– Agent æ‰§è¡Œå¼•æ“å‘å‡ºçš„æ‰€æœ‰äº‹ä»¶ã€‚
æ¯ä¸ªæ„å»ºå‡½æ•°è¿”å›ä¸å‰ç«¯ SSEEvent ç±»å‹å…¼å®¹çš„ dictã€‚
"""
import json
import logging
import time
from typing import Optional

logger = logging.getLogger(__name__)


def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬çš„ token æ•°ï¼ˆç»éªŒå…¬å¼ï¼Œé€‚ç”¨äºå¤§å¤šæ•°æ¨¡å‹ï¼‰ã€‚

    ä¸åŒ LLM çš„ tokenizer å„ä¸ç›¸åŒï¼Œç²¾ç¡®è®¡ç®—éœ€è¦å¼•å…¥å¯¹åº”çš„åº“ï¼ˆå¦‚ tiktokenï¼‰ã€‚
    è¿™é‡Œä½¿ç”¨ç»éªŒå…¬å¼è¿›è¡Œç²—ç•¥ä¼°ç®—ï¼Œè¯¯å·®é€šå¸¸åœ¨ 20% ä»¥å†…ï¼Œè¶³å¤Ÿ debug å‚è€ƒã€‚

    ç»éªŒå€¼ï¼š
    - ä¸­æ–‡ï¼šçº¦ 1.5 å­—ç¬¦ â‰ˆ 1 token
    - è‹±æ–‡/ç¬¦å·ï¼šçº¦ 4 å­—ç¬¦ â‰ˆ 1 token
    """
    if not text:
        return 0
    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°
    chinese_count = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    other_count = len(text) - chinese_count
    # ä¸­æ–‡çº¦ 1.5 å­—ç¬¦/tokenï¼Œå…¶ä»–çº¦ 4 å­—ç¬¦/token
    return int(chinese_count / 1.5 + other_count / 4)

# äº‹ä»¶ç±»å‹å¸¸é‡
TOKEN = "token"
TOOL_START = "tool_start"
TOOL_END = "tool_end"
LLM_START = "llm_start"
LLM_END = "llm_end"
DONE = "done"
ERROR = "error"
PLAN_CREATED = "plan_created"
PLAN_UPDATED = "plan_updated"
PLAN_REVISED = "plan_revised"
PLAN_APPROVAL_REQUEST = "plan_approval_request"
PHASE = "phase"

# å·¥å…·åŠ¨æœºæ˜ å°„ï¼ˆä¸­æ–‡æ˜¾ç¤ºåï¼‰
TOOL_MOTIVATIONS = {
    "read_file": "è¯»å–æ–‡ä»¶å†…å®¹",
    "write_file": "å†™å…¥æ–‡ä»¶",
    "terminal": "æ‰§è¡Œç»ˆç«¯å‘½ä»¤",
    "python_repl": "æ‰§è¡Œ Python ä»£ç ",
    "search_knowledge_base": "æœç´¢çŸ¥è¯†åº“",
    "memory_search": "æœç´¢è®°å¿†",
    "memory_write": "å†™å…¥è®°å¿†",
    "fetch_url": "è·å–ç½‘é¡µå†…å®¹",
    "plan_create": "åˆ›å»ºä»»åŠ¡è®¡åˆ’",
}


def build_phase(phase_name: str, description: str, **extra) -> dict:
    """æ„å»ºé¢„å¤„ç†é˜¶æ®µäº‹ä»¶ï¼Œé€šçŸ¥å‰ç«¯å½“å‰å¤„äºå“ªä¸ªé˜¶æ®µã€‚

    Args:
        phase_name: é˜¶æ®µæ ‡è¯†ï¼ˆå¦‚ graph_config, tools, prompt, memory_recall, executionï¼‰
        description: é˜¶æ®µæè¿°æ–‡æ¡ˆ
        **extra: é™„åŠ æ•°æ®ï¼ˆå¦‚ memory_recall é˜¶æ®µçš„ items åˆ—è¡¨ï¼‰
    """
    evt = {"type": PHASE, "phase": phase_name, "description": description}
    evt.update(extra)
    return evt


def build_token(content: str) -> dict:
    return {"type": TOKEN, "content": content}


def build_tool_start(tool_name: str, tool_input, motivation: str = None) -> dict:
    if motivation is None:
        motivation = TOOL_MOTIVATIONS.get(tool_name, f"è°ƒç”¨å·¥å…·ï¼š{tool_name}")
    return {
        "type": TOOL_START,
        "tool": tool_name,
        "input": str(tool_input),
        "motivation": motivation,
    }


def build_tool_end(tool_name: str, output: str, cached: bool, duration_ms: int = None, sandbox: str = "local") -> dict:
    return {
        "type": TOOL_END,
        "tool": tool_name,
        "output": output,
        "cached": cached,
        "duration_ms": duration_ms,
        "sandbox": sandbox,
    }


def build_llm_start(call_id: str, node: str, model: str, input_text: str, motivation: str) -> dict:
    return {
        "type": LLM_START,
        "call_id": call_id,
        "node": node,
        "model": model,
        "input": input_text,  # ä¸æˆªæ–­ï¼Œå‰ç«¯ä¼šå¤„ç†æŠ˜å æ˜¾ç¤º
        "motivation": motivation,
    }


def build_llm_end(call_id: str, node: str, model: str, duration_ms: int,
                   tokens: dict, input_text: str, output_text: str) -> dict:
    return {
        "type": LLM_END,
        "call_id": call_id,
        "node": node,
        "model": model,
        "duration_ms": duration_ms,
        "input_tokens": tokens.get("input_tokens"),
        "output_tokens": tokens.get("output_tokens"),
        "total_tokens": tokens.get("total_tokens"),
        "input": input_text,  # ä¸æˆªæ–­ï¼Œå‰ç«¯ä¼šå¤„ç†æŠ˜å æ˜¾ç¤º
        "output": output_text,  # ä¸æˆªæ–­
    }


def build_done() -> dict:
    return {"type": DONE}


def build_error(message: str) -> dict:
    return {"type": ERROR, "content": message}


def build_plan_approval_request(plan_info: dict) -> dict:
    """æ„å»ºè®¡åˆ’å®¡æ‰¹è¯·æ±‚äº‹ä»¶ã€‚"""
    return {
        "type": PLAN_APPROVAL_REQUEST,
        "plan_id": plan_info.get("plan_id", ""),
        "title": plan_info.get("title", ""),
        "steps": plan_info.get("steps", []),
    }


# --- åŸå§‹äº‹ä»¶è¾…åŠ©å‡½æ•°ï¼ˆä» LangGraph astream_events æå–æ•°æ®ï¼‰ ---

def build_tool_start_from_raw(event: dict) -> dict:
    """ä» LangGraph on_tool_start äº‹ä»¶æ„å»º tool_startã€‚"""
    tool_name = event.get("name", "")
    tool_input = (event.get("data") or {}).get("input", {})
    return build_tool_start(tool_name, tool_input)


def build_tool_end_from_raw(event: dict, duration_ms: Optional[int] = None) -> dict:
    """ä» LangGraph on_tool_end äº‹ä»¶æ„å»º tool_endã€‚"""
    tool_name = event.get("name", "")
    tool_output = (event.get("data") or {}).get("output", "")

    if hasattr(tool_output, 'content'):
        output_str = str(tool_output.content)
    else:
        output_str = str(tool_output)

    output_str = output_str[:2000]

    # æ£€æµ‹ [DOCKER] å‰ç¼€ï¼Œæ ‡è®°æ‰§è¡Œç¯å¢ƒ
    sandbox = "local"
    if output_str.startswith('[DOCKER]'):
        sandbox = "docker"
        output_str = output_str[8:]  # å»æ‰ [DOCKER] å‰ç¼€
        logger.info(f"ğŸ³ Docker æ²™ç®±æ‰§è¡Œ: {tool_name}")

    is_cached = output_str.startswith('[CACHE_HIT]')
    if is_cached:
        logger.info(f"âœ“ å·¥å…·ç¼“å­˜å‘½ä¸­: {tool_name}")

    return build_tool_end(tool_name, output_str, is_cached, duration_ms, sandbox)


def build_llm_end_from_raw(event: dict, tracked: dict) -> dict:
    """ä» LangGraph on_chat_model_end äº‹ä»¶ + è¿½è¸ªæ•°æ®æ„å»º llm_endã€‚"""
    run_id = event.get("run_id", "")
    output_msg = (event.get("data") or {}).get("output", None)
    duration_ms = int((time.time() - tracked["start_time"]) * 1000)

    # æå– Token ç”¨é‡ï¼ˆä¼˜å…ˆä½¿ç”¨ API è¿”å›çš„çœŸå®å€¼ï¼Œå¦åˆ™ä½¿ç”¨ä¼°ç®—å€¼ï¼‰
    tokens = {}
    tokens_estimated = False
    if output_msg and hasattr(output_msg, "usage_metadata") and output_msg.usage_metadata:
        um = output_msg.usage_metadata
        tokens = {
            "input_tokens": getattr(um, "input_tokens", None) or (um.get("input_tokens") if isinstance(um, dict) else None),
            "output_tokens": getattr(um, "output_tokens", None) or (um.get("output_tokens") if isinstance(um, dict) else None),
            "total_tokens": getattr(um, "total_tokens", None) or (um.get("total_tokens") if isinstance(um, dict) else None),
        }

    # æå–è¾“å‡ºæ–‡æœ¬
    output_parts = []
    if output_msg:
        if hasattr(output_msg, "content"):
            content = output_msg.content
            if isinstance(content, list):
                content_str = " ".join(
                    item.get("text", str(item)) if isinstance(item, dict) else str(item)
                    for item in content
                )
            else:
                content_str = str(content) if content else ""
            if content_str.strip():
                output_parts.append(content_str)

        tool_calls = []
        if hasattr(output_msg, "tool_calls") and output_msg.tool_calls:
            for tc in output_msg.tool_calls:
                # æ”¯æŒå­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼ï¼ˆä¸åŒ LLM è¿”å›æ ¼å¼å¯èƒ½ä¸åŒï¼‰
                if isinstance(tc, dict):
                    name = tc.get("name", "unknown")
                    args = tc.get("args", tc.get("arguments", ""))
                else:
                    # å¯¹è±¡æ ¼å¼ï¼šä¼˜å…ˆå– name/argsï¼Œå…¶æ¬¡å– function.name/function.arguments
                    name = getattr(tc, "name", None)
                    if name is None and hasattr(tc, "function"):
                        func = tc.function
                        name = func.get("name") if isinstance(func, dict) else getattr(func, "name", "unknown")
                    name = name or "unknown"

                    args = getattr(tc, "args", None) or getattr(tc, "arguments", None)
                    if args is None and hasattr(tc, "function"):
                        func = tc.function
                        args = func.get("arguments") if isinstance(func, dict) else getattr(func, "arguments", "")
                    args = args or ""

                tc_info = {
                    "name": name,
                    "arguments": json.dumps(args, ensure_ascii=False) if isinstance(args, dict) else str(args),
                }
                tool_calls.append(tc_info)

        if tool_calls:
            output_parts.append("[TOOL_CALLS]: " + json.dumps(tool_calls, ensure_ascii=False, indent=2))

        if not output_parts and hasattr(output_msg, "additional_kwargs") and output_msg.additional_kwargs:
            output_parts.append(str(output_msg.additional_kwargs))

        if not output_parts:
            output_parts.append(str(output_msg))

    output_text = "\n\n".join(output_parts) if output_parts else "(æ— å†…å®¹)"

    # å¦‚æœ API æ²¡æœ‰è¿”å› token ä¿¡æ¯ï¼Œä½¿ç”¨ä¼°ç®—å€¼
    # æµå¼è¾“å‡ºæ—¶ usage_metadata é€šå¸¸ä¸ºç©ºï¼Œå› æ­¤éœ€è¦æœ¬åœ°ä¼°ç®—
    input_text = tracked["input"]
    if not tokens.get("total_tokens"):
        tokens_estimated = True
        est_input = estimate_tokens(input_text)
        est_output = estimate_tokens(output_text)
        tokens = {
            "input_tokens": est_input,
            "output_tokens": est_output,
            "total_tokens": est_input + est_output,
        }

    from model_pool import resolve_model
    model_name = resolve_model("llm").get("model", "unknown")

    result = build_llm_end(
        call_id=run_id[:12],
        node=tracked["node"],
        model=model_name,
        duration_ms=duration_ms,
        tokens=tokens,
        input_text=input_text,
        output_text=output_text,
    )
    # æ ‡è®° token æ˜¯å¦ä¸ºä¼°ç®—å€¼ï¼Œå‰ç«¯å¯æ®æ­¤æ˜¾ç¤ºä¸åŒæ ·å¼
    result["tokens_estimated"] = tokens_estimated

    # è®¡ç®—æˆæœ¬ï¼ˆåŸºäº OpenRouter å®šä»·æ•°æ®ï¼‰
    try:
        from pricing import pricing_manager
        cost_info = pricing_manager.calculate_cost(
            model=model_name,
            input_tokens=tokens.get("input_tokens", 0),
            output_tokens=tokens.get("output_tokens", 0),
        )
        if cost_info:
            result["input_cost"] = cost_info["input_cost"]
            result["output_cost"] = cost_info["output_cost"]
            result["total_cost"] = cost_info["total_cost"]
            result["cost_estimated"] = tokens_estimated  # æˆæœ¬æ˜¯å¦åŸºäºä¼°ç®—çš„ token
            # æ¨¡å‹è¯¦æƒ…ï¼ˆç”¨äºå‰ç«¯æ‚¬åœæ˜¾ç¤ºï¼‰
            if cost_info.get("model_info"):
                result["model_info"] = cost_info["model_info"]
    except Exception as e:
        logger.debug(f"æˆæœ¬è®¡ç®—å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    return result


def serialize_sse(event: dict) -> str:
    """å°†äº‹ä»¶ dict åºåˆ—åŒ–ä¸º SSE æ ¼å¼ã€‚æ‰€æœ‰ SSE è¾“å‡ºçš„å”¯ä¸€å…¥å£ã€‚"""
    return f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
