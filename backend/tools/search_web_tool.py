"""Search Web Tool - DuckDuckGo æœç´¢å·¥å…·ï¼Œç”¨äºè·å–äº’è”ç½‘å®æ—¶ä¿¡æ¯ã€‚"""
import logging
from langchain_core.tools import tool

logger = logging.getLogger(__name__)


@tool
def search_web(query: str) -> str:
    """åœ¨äº’è”ç½‘ä¸Šæœç´¢ä¿¡æ¯ï¼Œè¿”å›ç›¸å…³ç»“æœæ‘˜è¦ã€‚

    ä½¿ç”¨ DuckDuckGo æœç´¢å¼•æ“æŸ¥æ‰¾æœ€æ–°èµ„è®¯ã€æŠ€æœ¯æ–‡æ¡£ã€è§£å†³æ–¹æ¡ˆç­‰ã€‚
    é€‚ç”¨äºéœ€è¦å®æ—¶ä¿¡æ¯æˆ–ä¸ç¡®å®šå…·ä½“ URL çš„åœºæ™¯ã€‚

    Args:
        query: æœç´¢å…³é”®è¯æˆ–é—®é¢˜æè¿°ï¼ˆå­—ç¬¦ä¸²ï¼‰

    Returns:
        æœç´¢ç»“æœæ‘˜è¦ï¼ˆåŒ…å«æ ‡é¢˜ã€é“¾æ¥å’Œæè¿°ï¼‰ï¼Œæˆ–é”™è¯¯ä¿¡æ¯ã€‚

    Examples:
        - "Python asyncio æœ€ä½³å®è·µ"
        - "FastAPI streaming response ç¤ºä¾‹"
        - "LangChain agent å·¥å…·è°ƒç”¨æ•™ç¨‹"
    """
    if not query or not query.strip():
        return "âŒ é”™è¯¯ï¼šæœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º"

    # æ£€æŸ¥ç¼“å­˜ï¼ˆæœç´¢ç»“æœç›¸å¯¹ç¨³å®šï¼Œå¯ç¼“å­˜ï¼‰
    try:
        from cache import url_cache
        # ä½¿ç”¨æŸ¥è¯¢ä½œä¸ºç¼“å­˜é”®ï¼ˆæ·»åŠ å‰ç¼€åŒºåˆ† URL ç¼“å­˜ï¼‰
        cache_key = f"search:{query.strip()}"
        cached = url_cache.get_cached_url(cache_key)
        if cached is not None:
            logger.info(f"âœ“ æœç´¢ç¼“å­˜å‘½ä¸­: {query[:50]}")
            return "[CACHE_HIT]" + cached
    except Exception as e:
        logger.warning(f"ç¼“å­˜æ£€æŸ¥å¤±è´¥ï¼ˆå°†æ‰§è¡Œæœç´¢ï¼‰: {e}")

    try:
        # å¯¼å…¥ DuckDuckGo æœç´¢å·¥å…·ï¼ˆä½¿ç”¨æ–°åŒ…å ddgsï¼‰
        from ddgs import DDGS

        # æ‰§è¡Œæœç´¢ï¼ˆä¼˜åŒ–ä¸­æ–‡æœç´¢ï¼‰
        with DDGS() as ddgs:
            results = list(ddgs.text(
                query=query.strip(),     # æ–° API ä½¿ç”¨ query å‚æ•°
                safesearch='moderate',   # é€‚åº¦å®‰å…¨æœç´¢
                max_results=8,           # é™åˆ¶ç»“æœæ•°é‡é¿å… token æµªè´¹
            ))

        if not results:
            return f"âš ï¸ æœªæ‰¾åˆ°ç›¸å…³ç»“æœï¼š{query}"

        # æ ¼å¼åŒ–æœç´¢ç»“æœ
        formatted_results = []
        for i, result in enumerate(results, 1):
            title = result.get("title", "æ— æ ‡é¢˜")
            link = result.get("href", "")
            snippet = result.get("body", "")

            formatted_results.append(
                f"{i}. **{title}**\n"
                f"   é“¾æ¥: {link}\n"
                f"   æ‘˜è¦: {snippet}\n"
            )

        output = (
            f"ğŸ” æœç´¢å…³é”®è¯: {query}\n\n"
            + "\n".join(formatted_results)
        )

        # é™åˆ¶è¾“å‡ºé•¿åº¦
        if len(output) > 4000:
            output = output[:4000] + "\n\n...[ç»“æœå·²æˆªæ–­ï¼Œä»…æ˜¾ç¤ºå‰ 4000 å­—ç¬¦]"

        # ç¼“å­˜æœç´¢ç»“æœ
        try:
            from cache import url_cache
            cache_key = f"search:{query.strip()}"
            url_cache.cache_url(cache_key, output)
        except Exception as e:
            logger.warning(f"ç¼“å­˜æœç´¢ç»“æœå¤±è´¥: {e}")

        return output

    except ImportError:
        return (
            "âŒ é”™è¯¯ï¼šDuckDuckGo æœç´¢åº“æœªå®‰è£…\n"
            "è¯·è¿è¡Œ: pip install ddgs"
        )
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return f"âŒ æœç´¢å¤±è´¥: {str(e)}"


def create_search_web_tool():
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºç½‘é¡µæœç´¢å·¥å…·å®ä¾‹ã€‚"""
    return search_web
